{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4776263",
   "metadata": {},
   "source": [
    "### 모델\n",
    "초기 계획은 catboost, xgboost, tabnet을 이용해서 pseudo labeling을 만들고 pseudo labeling을 가지고 semi-supervised learning을 수행하는 것 이었습니다. 하지만, pseudo label을 함께 이용하면 오히려 성능이 더 떨어졌고, 세 개의 모델 중 가장 성능이 좋았던 catboost의 결과물을 제출 했습니다. (catboost, xgboost, tabnet의 모든 데이터 전처리는 모델에 적합하게 다르게 해주었습니다.)  \n",
    "참고) catboost 단일 모델 private score 0.6363, pseudo label 후 private score : 0.6605  \n",
    "적용하기 전 부터 데이터의 특성상 대부분의 변수가 oridnal 한 관계랑 상관 없이, 특정 시간 혹은 특정 장소가 연착에 영향을 미친다고 생각했기 때문에 catboost가 가장 성능이 좋을 것이라고 생각했으며, 실제 적용했을 때도 가장 성능이 좋았습니다.\n",
    "### 데이터 학습 : w/o optimization, self weight 이용\n",
    "optimization vs w/o optimization : 본 모델은 optimization 을 적용하지 않은 모델을 사용했으며, 상세 이유는 아래 training 부분에 나와있습니다.  \n",
    "catboost의 default loss_function이 logloss여서, 따로 설정하지 않고 바로 사용했습니다.  \n",
    "class imbalance 해결을 위해 training data에서 라벨 별 가중치를 구해서 모델 학습할 때 사용했습니다.  \n",
    "(catboost의 auto_class_weights parameter가 있는데, True로 놓으면 거의 유사한 방식으로 동작할 것 으로 예상합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost==1.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20163814",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eebff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Fixed Seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b908d2",
   "metadata": {},
   "source": [
    "## (csv를 parquet 형태로 저장하지 않으신 분만 실행하세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # baseline을 참고했으며, parquet으로 저장하고 실행하면 csv보다 매우 빠르게 데이터 처리가 가능합니다 :)\n",
    "\n",
    "# def csv_to_parquet(csv_path, save_name):\n",
    "#     df = pd.read_csv(csv_path)\n",
    "#     df.to_parquet(f'./{save_name}.parquet')\n",
    "#     del df\n",
    "#     gc.collect()\n",
    "#     print(save_name, 'Done.')\n",
    "    \n",
    "# csv_to_parquet('./train.csv', 'train')\n",
    "# csv_to_parquet('./test.csv', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba67ec1",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e1ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('./train.parquet')\n",
    "test = pd.read_parquet('./test.parquet')\n",
    "sample_submission = pd.read_csv('./sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38788d9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25639f7",
   "metadata": {},
   "source": [
    "### 비행기 연착과 관련되는 데이터의 특성을 생각하며 전처리를 해주었습니다. 정답은 없으며 제 insight를 최대한 활용했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003e7fe",
   "metadata": {},
   "source": [
    "## train info (참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5c1c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count    Dtype  \n",
      "---  ------                    --------------    -----  \n",
      " 0   ID                        1000000 non-null  object \n",
      " 1   Month                     1000000 non-null  int64  \n",
      " 2   Day_of_Month              1000000 non-null  int64  \n",
      " 3   Estimated_Departure_Time  890981 non-null   float64\n",
      " 4   Estimated_Arrival_Time    890960 non-null   float64\n",
      " 5   Cancelled                 1000000 non-null  int64  \n",
      " 6   Diverted                  1000000 non-null  int64  \n",
      " 7   Origin_Airport            1000000 non-null  object \n",
      " 8   Origin_Airport_ID         1000000 non-null  int64  \n",
      " 9   Origin_State              890985 non-null   object \n",
      " 10  Destination_Airport       1000000 non-null  object \n",
      " 11  Destination_Airport_ID    1000000 non-null  int64  \n",
      " 12  Destination_State         890921 non-null   object \n",
      " 13  Distance                  1000000 non-null  int64  \n",
      " 14  Airline                   891080 non-null   object \n",
      " 15  Carrier_Code(IATA)        891010 non-null   object \n",
      " 16  Carrier_ID(DOT)           891003 non-null   float64\n",
      " 17  Tail_Number               1000000 non-null  object \n",
      " 18  Delay                     255001 non-null   object \n",
      " 19  Day                       1000000 non-null  object \n",
      "dtypes: float64(3), int64(7), object(10)\n",
      "memory usage: 152.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3f9bb",
   "metadata": {},
   "source": [
    "## 1. Month, Days 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c43d7f",
   "metadata": {},
   "source": [
    "   비행기 연착과 관련있는 특성을 생각해보면, **특정 기념일에 따라 (예를 들어, 크리스마스) 연착이 될 관련성이 가장 크다**고 생각(가정)했습니다. \n",
    "    따라서, Month와 Day를 따로 생각하기 보다 이것을 합쳐서 366일(해당 연도가 윤년일 경우 고려)으로 표현했습니다.\n",
    "    이런 가정 내에서는 날짜의 순서는 전혀 관계없으며 특정 일만 카테고리 형식으로 처리합니다(모델에서)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee864f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day Done.\n"
     ]
    }
   ],
   "source": [
    "def to_days(x):\n",
    "    month_to_days = {1:0, 2:31, 3:60, 4:91, 5:121, 6:152, 7:182, 8:213, 9:244, 10:274, 11:305, 12:335}\n",
    "    return month_to_days[x]\n",
    "\n",
    "train.loc[:, 'Day'] = train['Month'].apply(lambda x: to_days(x))\n",
    "train['Day'] = train['Day'] + train['Day_of_Month']\n",
    "\n",
    "test.loc[:, 'Day'] = test['Month'].apply(lambda x: to_days(x))\n",
    "test['Day'] = test['Day'] + test['Day_of_Month']\n",
    "\n",
    "train = train.astype({'Day':object})\n",
    "test = test.astype({'Day':object})\n",
    "\n",
    "print(\"Day Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0098851",
   "metadata": {},
   "source": [
    "## 2. Carrier_ID(DOT) 처리 with Airline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f7b19",
   "metadata": {},
   "source": [
    "데이터의 설명을 보면 Carrier_ID(DOT)은 해당 항공사(Airline) 별로 하나가 할당 됩니다(1대1 대응). 따라서, 둘 중 하나만 있어도 분류하는데 지장이 없으며(두 데이터는 서로 완전종속이기 때문에), 각각 891080개의 non-null 값을 보면, 어쩌면, 두 개 모두 결측치가 아닌 이상, 데이터 복구가 가능하다고 가정을 할 수 있습니다. **둘 다 상관없지만 저는 숫자로 표현된게 마음이 편해서 Carrier_ID(DOT)을 사용**하기로 마음먹었습니다. 따라서, 먼저 복구 가능한 데이터의 개수 (Airline이 존재하면서, Carrier_ID(DOT)이 존재 안하는 row의 개수)를 확인한 후, Airline과 Carrier_ID(DOT)을 이어주는 dictionary 를 만들어서 가능한 Carrier_ID(DOT)를 복구합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b819d",
   "metadata": {},
   "source": [
    "### Airline 을 통해 Carrier_ID(DOT) 복구 가능한 데이터의 개수 파악 및 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558c81eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrier_ID(DOT) 복구 가능한 데이터의 개수 : 97114\n"
     ]
    }
   ],
   "source": [
    "cond1 = train['Carrier_ID(DOT)'].isnull()\n",
    "cond2 = ~train['Airline'].isnull()\n",
    "print(\"Carrier_ID(DOT) 복구 가능한 데이터의 개수 :\", len(train.loc[cond1 & cond2, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639b6b3",
   "metadata": {},
   "source": [
    "### Airline to Carrier_ID(DOT) dictinary 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c21739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# airline to carrier id, dictinary 만들기\n",
    "# 모두 데이터가 존재하는 열에서 Dict[Airline] = carrier_ID(DOT) 가 되도록 dictionary 생성\n",
    "airline_to_cid = {}\n",
    "for _, row in train[(~train['Carrier_ID(DOT)'].isnull() & ~train['Airline'].isnull())].iterrows():\n",
    "    airline_to_cid[row['Airline']] = row['Carrier_ID(DOT)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d40c97",
   "metadata": {},
   "source": [
    "### Carrier_ID(DOT) 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73782442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복구하기\n",
    "def to_cid(x):\n",
    "    return airline_to_cid[x]\n",
    "\n",
    "cond1 = train['Carrier_ID(DOT)'].isnull()\n",
    "cond2 = ~train['Airline'].isnull()\n",
    "train.loc[cond1&cond2, 'Carrier_ID(DOT)'] = train.loc[cond1&cond2, 'Airline'].apply(lambda x: to_cid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6dbfb0",
   "metadata": {},
   "source": [
    "### 복구 안 된 Carrier_ID는 학습에 방해되므로 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc7bd12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복구 안 된 row 빼기\n",
    "train = train.dropna(subset=['Carrier_ID(DOT)'], how='any', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9df0c",
   "metadata": {},
   "source": [
    "### Test Data 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4e5a8",
   "metadata": {},
   "source": [
    "test data의 경우 복구 안 된 row를 빼 버리면 안됩니다. 복구 안된 row도 예측을 해야되기 때문이죠.\n",
    "따라서, Airline, Carrier_ID(DOT) 둘 다 없는 row는 Carrier_ID(DOT)에 최빈 값의 Carrier_ID(DOT)을 채워주도록 하고 Airline 으로부터 복구 가능한 Carrier_ID(DOT)은 Training과 마찬가지로 복구해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e8d1ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cid Done.\n"
     ]
    }
   ],
   "source": [
    "# (Test Data Only)\n",
    "# Airline, Carrier_Code 둘 다 없으면 최빈 값으로 대체\n",
    "NaN_col = ['Carrier_ID(DOT)']\n",
    "cond1 = test['Airline'].isnull()\n",
    "cond2 = test['Carrier_ID(DOT)'].isnull()\n",
    "\n",
    "for col in NaN_col:\n",
    "    mode = test[col].mode()[0]\n",
    "    test.loc[cond1&cond2, col] = mode\n",
    "\n",
    "# 나머진 Airline에서 대체\n",
    "cond1 = test['Carrier_ID(DOT)'].isnull()\n",
    "cond2 = ~test['Airline'].isnull()\n",
    "test.loc[cond1&cond2, 'Carrier_ID(DOT)'] = test.loc[cond1&cond2, 'Airline'].apply(lambda x: to_cid(x))\n",
    "\n",
    "print(\"Cid Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69f73b",
   "metadata": {},
   "source": [
    "## 3. 제거할 Columns 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7287f08",
   "metadata": {},
   "source": [
    "Month, Day_of_Month 는 Day의 데이터로 합쳐졌으니 제거합니다.  \n",
    "Cancelled, Diverted 는 모두 0이므로 의미없는 값이므로 제거합니다.  \n",
    "Origin_Airport, Destination_Airport 는 Origin_Airport_ID와 Destination_Airport_ID와 1대1대응 이므로 제거합니다.  \n",
    "Carrier_Code(IATA)는 Airline 별로 N:1로 할당 된 값이므로, 큰 의미가 없습니다. 제거합니다.  \n",
    "State 정보 보다는 Origin_Airport_ID가 중요하다고 생각되어서 (미국 주는 너무 커서 의미가 없다고 생각했음) 제거했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21473508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop Done.\n"
     ]
    }
   ],
   "source": [
    "col_drop = ['Month', 'Day_of_Month', 'Cancelled', 'Diverted', 'Origin_Airport', 'Destination_Airport', 'Carrier_Code(IATA)', 'Airline', 'Origin_State', 'Destination_State']\n",
    "train = train.drop(col_drop, axis=1)\n",
    "test = test.drop(col_drop, axis=1)\n",
    "print(\"Drop Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43633371",
   "metadata": {},
   "source": [
    "## 4. Estimated Departure Time (EDT), Estimated Arrival Time (EAT) 복구"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c191161b",
   "metadata": {},
   "source": [
    "Airline, Carrier_ID(DOT)의 경우와 비슷하게 EDT &rarr; EAT 복구, EAT &rarr; EDT 복구가 가능합니다.  \n",
    "복구 방법은 **결측치가 없는 Origin_Airport_ID &rarr; Destination_Airport_ID 의 정보를 이용**하는 것 입니다.  \n",
    "본 데이터를 살펴보신분들은 아시겠지만, EDT보다 EAT가 낮은 경우도 있습니다. (-시차 때문에 발생) 하지만, 이것과 별개로 특정 출발지 &rarr; 도착지의 관계에서는 EAT-EDT가 평균적으로 비슷할 것 입니다. (마이너스인 경우에도 항상 마이너스기 때문에 비슷할 것) 언제 출발이던 인천 &rarr; 오사카의 걸리는 시간은 비슷하기 때문입니다.  \n",
    "따라서 기존 데이터로부터 Origin_Airport_ID (=OAID), Origin_Departure_ID (=ODID)의 쌍에 대해 걸리는 평균 시간을 구하면 EDT, EAT 둘 중 하나만 알고 있으면 서로 데이터 복구가 가능합니다.  \n",
    "이 과정에서, 계산을 용이하게 하기 위해 hour:minute의 데이터를 모두 minute으로 변경해주었고 (하루 24시 = 1440분) 이 과정에서 EAT-EDT 했을 때, 음수가 나올 수 있는데 이것을 처리하기 위해 modular 연산을 이용했습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccee055",
   "metadata": {},
   "source": [
    "### Arrival Time & Departure Time 둘 다 60분 * 24 = 1440 계로 바꿔주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9695c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_minutes(x):\n",
    "    x = int(x)\n",
    "    x = str(x)\n",
    "    if len(x) > 2:\n",
    "        hours, mins = int(x[:-2]), int(x[-2:])\n",
    "    else:\n",
    "        hours, mins = 0, int(x[-2:])\n",
    "    return hours*60+mins\n",
    "\n",
    "estimated_times = ['Estimated_Departure_Time', 'Estimated_Arrival_Time']\n",
    "\n",
    "for ET in estimated_times:\n",
    "    cond = ~train[ET].isnull()\n",
    "    train.loc[cond, ET] = train.loc[cond, ET].apply(lambda x: to_minutes(x))\n",
    "    cond2 = ~test[ET].isnull()\n",
    "    test.loc[cond2, ET] = test.loc[cond2, ET].apply(lambda x: to_minutes(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a35802",
   "metadata": {},
   "source": [
    "### EAT, EDT 모두 없는 값은 Training에 도움이 안 되므로 빼주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b7b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['Estimated_Arrival_Time', 'Estimated_Departure_Time'], how ='all', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2cf794",
   "metadata": {},
   "source": [
    "### (OAID, DAID)를 키로 갖고, 평균 비행시간을 값으로 갖는 dictionary 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a1bbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_flying = defaultdict(int)\n",
    "time_number = defaultdict(int)\n",
    "\n",
    "cond_arr2 = ~train['Estimated_Arrival_Time'].isnull()\n",
    "cond_dep2 = ~train['Estimated_Departure_Time'].isnull()\n",
    "\n",
    "for _, row in train.loc[cond_arr2 & cond_dep2, :].iterrows():\n",
    "    OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
    "    time_flying[(OAID,DAID)] += (row['Estimated_Arrival_Time'] - row['Estimated_Departure_Time'])%1440 # 하루 최대는 1440분\n",
    "    time_number[(OAID,DAID)] += 1\n",
    "    \n",
    "    \n",
    "for key in time_flying.keys():\n",
    "    time_flying[key] /= time_number[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591a836",
   "metadata": {},
   "source": [
    "### Dictionary를 이용해 EAT, EDT 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "036ba3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.loc[train['Estimated_Departure_Time'].isnull(),].iterrows():\n",
    "    OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
    "    train.loc[index,'Estimated_Departure_Time'] = \\\n",
    "        (train.loc[index]['Estimated_Arrival_Time'] - time_flying[(OAID, DAID)])%1440\n",
    "    \n",
    "for index, row in train.loc[train['Estimated_Arrival_Time'].isnull(),].iterrows():\n",
    "    OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
    "    train.loc[index,'Estimated_Arrival_Time'] = \\\n",
    "        (train.loc[index]['Estimated_Departure_Time'] + time_flying[(OAID, DAID)])%1440"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94614cc8",
   "metadata": {},
   "source": [
    "### Test Data 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c23357",
   "metadata": {},
   "source": [
    "test data의 경우 복구 안 된 row를 빼 버리면 안됩니다. 복구 안된 row도 예측을 해야되기 때문이죠.  \n",
    "따라서, EAT, EDT 둘 다 없는 row는 각각의 최빈값을 채워주도록 하고 나머지는 복구를 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ca87233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDT, EAT Done.\n"
     ]
    }
   ],
   "source": [
    "# (Test Data Only)\n",
    "# 둘 다 없으면 최빈값으로 대체\n",
    "cond_1 = test['Estimated_Departure_Time'].isnull()\n",
    "cond_2 = test['Estimated_Arrival_Time'].isnull()\n",
    "\n",
    "mode = test['Estimated_Departure_Time'].mode()[0]\n",
    "mode2 = test['Estimated_Arrival_Time'].mode()[0]\n",
    "test.loc[cond_1&cond_2, ['Estimated_Departure_Time', 'Estimated_Arrival_Time']] = mode, mode2\n",
    "\n",
    "\n",
    "# Departure만 없을 때,\n",
    "for index, row in test.loc[test['Estimated_Departure_Time'].isnull(),].iterrows():\n",
    "    OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
    "    test.loc[index,'Estimated_Departure_Time'] = \\\n",
    "        (test.loc[index]['Estimated_Arrival_Time'] - time_flying[(OAID, DAID)])%1440\n",
    "    \n",
    "\n",
    "# Arrival만 없을 때,\n",
    "for index, row in test.loc[test['Estimated_Arrival_Time'].isnull(),].iterrows():\n",
    "    OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
    "    test.loc[index,'Estimated_Arrival_Time'] = \\\n",
    "        (test.loc[index]['Estimated_Departure_Time'] + time_flying[(OAID, DAID)])%1440\n",
    "\n",
    "    \n",
    "# 모두 int로 바꾼다.\n",
    "estimated_times = ['Estimated_Departure_Time', 'Estimated_Arrival_Time']\n",
    "train = train.astype({'Estimated_Departure_Time':int, 'Estimated_Arrival_Time':int})\n",
    "test = test.astype({'Estimated_Departure_Time':int, 'Estimated_Arrival_Time':int})\n",
    "for ET in estimated_times:\n",
    "    train.loc[train[ET] == 1440, ET] = 0\n",
    "    test.loc[test[ET] == 1440, ET] = 0\n",
    "\n",
    "\n",
    "print(\"EDT, EAT Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431ab96",
   "metadata": {},
   "source": [
    "## Object화 for CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a769e3d",
   "metadata": {},
   "source": [
    "### EDT, EAT 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea311f",
   "metadata": {},
   "source": [
    "**특정 시간**이 비행기 연착에 영향을 미칠 것으로 생각했습니다. 따라서 EDT, EAT경우 30분 단위로 48개의 bin에 담아서 object화 해주었습니다. 그렇게 함으로써 ordinal한 관계는 전혀 없으면서 비슷한 시간대(30분 단위)는 같은 특성을 갖도록 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a99ce3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDT, EAT Done.\n"
     ]
    }
   ],
   "source": [
    "# EDT, EAT 48개의 bins에 담으면 된다. 1440(60*24) 계니까, 48씩 끊어서 하면 될 듯\n",
    "estimate_times = ['Estimated_Departure_Time', 'Estimated_Arrival_Time']\n",
    "names = {'Estimated_Departure_Time':'EDT', 'Estimated_Arrival_Time':'EAT'}\n",
    "for ET in estimated_times:\n",
    "    for i in range(48):\n",
    "        train.loc[train[ET].between(i*30, (i+1)*30, 'left'), names[ET]] = i\n",
    "        test.loc[test[ET].between(i*30, (i+1)*30, 'left'), names[ET]] = i\n",
    "\n",
    "train = train.astype({'EDT':int, 'EAT':int})\n",
    "test = test.astype({'EDT':int, 'EAT':int})\n",
    "\n",
    "train = train.drop(['Estimated_Departure_Time', 'Estimated_Arrival_Time'], axis=1)\n",
    "test = test.drop(['Estimated_Departure_Time', 'Estimated_Arrival_Time'], axis=1)\n",
    "\n",
    "print(\"EDT, EAT Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a83fe",
   "metadata": {},
   "source": [
    "### Distance 및 모든 값 object 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e6847",
   "metadata": {},
   "source": [
    "Distance는 사실, ordinal하게 상관관계가 있을 것으로 예상되었지만, catboost 특성을 고려하여 object화 해주었습니다. Object화 할 때, 모든 distance에 대해 카테고리를 나누면 너무 많아지기 때문에, 단위를 100개로 총 50개의 bin에 담았습니다.  \n",
    "나머지 (EDT, EAT, OAID, DAID, Carrier_ID(DOT))의 모든 값은 category가 맞다고 생각하였기 때문에 **(not ordinal이면서 특정 값이 영향을 미침)** 모두 object화 해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00da2bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance Done.\n",
      "CID Done.\n"
     ]
    }
   ],
   "source": [
    "for i in range(51):\n",
    "    train.loc[train['Distance'].between(i*100, (i+1)*100, 'left'), 'Distance'] = i\n",
    "    test.loc[test['Distance'].between(i*100, (i+1)*100, 'left'), 'Distance'] = i\n",
    "\n",
    "train = train.astype({'Distance':int})\n",
    "test = test.astype({'Distance':int})\n",
    "\n",
    "print(\"distance Done.\")\n",
    "\n",
    "train = train.astype({'Carrier_ID(DOT)':int})\n",
    "test = test.astype({'Carrier_ID(DOT)':int})\n",
    "\n",
    "train = train.astype({'EDT':object, 'EAT':object, 'Distance':object, 'Origin_Airport_ID':object, \\\n",
    "                     'Destination_Airport_ID':object, 'Carrier_ID(DOT)':object})\n",
    "test = test.astype({'EDT':object, 'EAT':object, 'Distance':object, 'Origin_Airport_ID':object, \\\n",
    "                     'Destination_Airport_ID':object, 'Carrier_ID(DOT)':object})\n",
    "\n",
    "print(\"CID Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef48d6a",
   "metadata": {},
   "source": [
    "# Modeling & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4fb47",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61304f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Prepared.\n"
     ]
    }
   ],
   "source": [
    "train = train.dropna()\n",
    "\n",
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "train.loc[:, 'Delay_num'] = train['Delay'].apply(lambda x: to_number(x, column_number))\n",
    "\n",
    "train_x = train.drop(columns=['ID', 'Delay', 'Delay_num'])\n",
    "train_y = train['Delay_num']\n",
    "test_x = test.drop(columns=['ID'])\n",
    "\n",
    "print('Training Prepared.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c43b4",
   "metadata": {},
   "source": [
    "## self weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5543c1",
   "metadata": {},
   "source": [
    "전체 데이터에서 delay된 데이터는 not_delay 데이터 보다 매우 적기 때문에 학습할 때, 이를 해결하기 위해 클래스 별 가중치를 계산하여 이것을 고려하여 주어서 학습하도록 했습니다. 이렇게 함으로써, delay, not_delay 데이터의 imbalance를 해결했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "394586e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : [0.1766316896968529, 0.8233683103031472]\n"
     ]
    }
   ],
   "source": [
    "counts = list(train_y.value_counts())\n",
    "class_weight = [counts[1]/sum(counts), counts[0]/sum(counts)]\n",
    "print(\"weight :\", class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2bd8f9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0c84f",
   "metadata": {},
   "source": [
    "### Optimization 여부 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c0b2f",
   "metadata": {},
   "source": [
    "Optimization을 해서 예상한 결과값도 있고, 하지 않은 결과값도 있습니다. 제출 csv는 optimization을 진행하지 않은 코드이기 때문에 이것으로 제출 합니다.\n",
    "optimization을 해보기도 했고 안 해보기도 했는데, optimization을 하지 않은 코드가 public 성능이 조금 더 좋아서, 이것을 제출했습니다. **(사실 올바른 모델 평가를 위해서는 optimization을 하고 내는게 더 성능이 좋을 것이라고 생각은 합니다.)**\n",
    "하지만, optimization을 위해서는 validation 세트가 필요하고 data를 0.8 / 0.2 이런식으로 나눠야 합니다. 전체 데이터에 delay 결측치가 많으므로, 최대한 많은 데이터를 보존하기 위해 optimization을 안하고 더 많은 데이터셋으로 학습한 코드를 냈네요.  \n",
    "따라서 아래와 같이 CatBoost 기본 모델과 self-weight를 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1aa321f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fdff5b46eb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [i for i in range(8)]\n",
    "model = CatBoostClassifier(random_seed=42, cat_features=cat_features, class_weights=class_weight, verbose=0)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59246f38",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dbeada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236864f0",
   "metadata": {},
   "source": [
    "## Save the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2511734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Done.\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame(data=y_pred, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('./results/catboost_self_weight2.csv', index=True)\n",
    "\n",
    "print(\"CSV Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404937a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
